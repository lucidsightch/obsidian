
![[Pasted image 20230611120927.png]]
![[Pasted image 20230611121034.png]
![[Pasted image 20230611121103.png]]
![[Pasted image 20230611121304.png]]
![[Pasted image 20230611121553.png]]
![[Pasted image 20230611121649.png]]

Обучить модель линейной регрессии, значит подобрать оптимальные коэффициенты Wn и свободный член, чтобы минимизириовать ошибку
![[Pasted image 20230617175139.png]]
![[Pasted image 20230617175215.png]]
![[Pasted image 20230617175303.png]]
 Матрица х - матрица признаков
 Вектор w - вектор весов модели
 Вектор y - вектор целевой переменнной, которую мы хотим предсказывать
 Вектор эпсилон - ошибка, от которой мы хотим избавиться(но полностью не можем)

Обучение метод наименьших квадратов:
![[Pasted image 20230617180415.png]]
![[Pasted image 20230620145714.png]]
![[Pasted image 20230620145748.png]]
![[Pasted image 20230620145904.png]]
![[Pasted image 20230620145917.png]]
![[Pasted image 20230620145921.png]]
(Не должно быть подвыборок обьектов на которых получаем ошибки которые сильно отличаются от остальной выборки)

![[Pasted image 20230620145945.png]]
Случайные ошибки должны быть не скореллированы (должны носить случайный характер и никаких зависимостей в них быть не должно)
![[Pasted image 20230620150014.png]]
![[Pasted image 20230620150105.png]]
![[Pasted image 20230620150116.png]]
![[Pasted image 20230620150144.png]]
![[Pasted image 20230620150231.png]]

https://www.youtube.com/watch?v=MM4onsNaLlI&ab_channel=StartCareerinDS
Продолжение про регуляризацию